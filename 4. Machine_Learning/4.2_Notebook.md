# OML Notebooks
**Oracle Machine Learning Notebooks** are a collaborative, web-based *interface* composed of paragraphs, for data scientists and analysts to perform machine learning, in this case, within Oracle Autonomous Database. They allow users to explore data, build models, and visualize results within a single, interactive environment. 

## Model Creation
Inside **OML** I clicked on *Menu* (the stacked bars â˜°) > *Notebooks* > *New Notebook*. This new Notebook was called **OML_Notebook_Regression**.

I then proceeded to running the following paragraphs for the creation of my regression model:

1. **Notebook title**

I used the 1st paragraph of the notebook to give a brief description of the project:

```md
# Regression Modeling to Predict Numerical Values

"This notebook shows how to predict numerical values using a multiple regression. Given demographic, purchase, and affinity card data for a set of customers, predict the number of years a customer remains at the same residence, as found in column YRS_RESIDENCE. Since YRS_RESIDENCE is a continuous variable, we will use the Generalized Linear Model algorithm."
```
*Project's Name and Description in **Markdown** format.*

![notebook](/Assets/oml_notebook.png)
*OML Notebook Paragraph 1.*

2. **Storing the object storage credentials**

I gave OML access to OCI Object Storage (where all of my files are) with a credential using my previously generated **Auth Token**. 

```sql
%script
begin
DBMS_CLOUD.create_credential (
    credential_name => 'OBJ_STORE_CRED',
    username => 'YOUR ORACLE CLOUD ACCOUNT USERNAME (EMAIL)',
    password => 'YOUR AUTH TOKEN'
);
end;
/
```

Remember to substitute this query with your own **username** and **Auth Token** (password).

![p.2](/Assets/p.2.png)
*OML Notebook Paragraph 2.*

3. **Create SUPPLEMENTARY table**

I created the **SUPPLEMENTARY_DEMOGRAPHICS** external table using its csv file (with that exact name) stored in my OCI Object Storage. Making sure I had no previous tables with that name.

```sql
%script
DROP TABLE SUPPLEMENTARY_DEMOGRAPHICS;

BEGIN
DBMS_CLOUD.CREATE_EXTERNAL_TABLE(
    table_name => 'SUPPLEMENTARY_DEMOGRAPHICS',
    credential_name => 'OBJ_STORE_CRED',
    file_uri_list => 'URL Path OF THE "SUPPLEMENTARY_DEMOGRAPHICS" CSV FILE STORED INSIDE THE DataLake_ObjectStorage BUCKET',
    format => json_object('type' value 'csv', 'skipheaders' value '1', 'ignoremissingcolumns' value 'true'),
    column_list => 'CUST_ID NUMBER,
                    EDUCATION VARCHAR2(21 BYTE) COLLATE USING_NLS_COMP,
                    OCCUPATION VARCHAR2(21 BYTE) COLLATE USING_NLS_COMP,
                    HOUSEHOLD_SIZE VARCHAR2(21 BYTE) COLLATE USING_NLS_COMP,
                    YRS_RESIDENCE NUMBER,
                    AFFINITY_CARD NUMBER(10,0),
                    BULK_PACK_DISKETTES NUMBER(10,0),
                    FLAT_PANEL_MONITOR NUMBER(10,0),
                    HOME_THEATER_PACKAGE NUMBER(10,0),
                    BOOKKEEPING_APPLICATION NUMBER(10,0),
                    PRINTER_SUPPLIES NUMBER(10,0),
                    Y_BOX_GAMES NUMBER(10,0),
                    OS_DOC_SET_KANJI NUMBER(10,0),
                    COMMENTS VARCHAR2(4000 BYTE) COLLATE USING_NLS_COMP'
);
END;
/
```

Remember to change the 'file_uri_list' to that of the **SUPPLEMENTARY_DEMOGRAPHICS** csv file URL from your own Object Storage.

![p.3](/Assets/p.3.png)
*OML Notebook Paragraph 3.*

4. **Cleanup Previous Runs and Create CUSTOMERS360**

I created the **CUSTOMERS360** customized table. Making sure I had no previous tables with that name.

```sql
%script
-- Drop any previously existing customized table for notebook repeatability
BEGIN
    EXECUTE IMMEDIATE 'DROP TABLE CUSTOMERS360';
EXCEPTION
    WHEN OTHERS THEN NULL;
END;
/

-- Join selected attributes from SH.CUSTOMERS and SH.SUPPLEMENTARY_DEMOGRAPHICS tables to create better 360 view of customer
CREATE TABLE CUSTOMERS360 AS
SELECT
    A.CUST_ID, A.CUST_GENDER, A.CUST_MARITAL_STATUS, A.CUST_YEAR_OF_BIRTH, A.CUST_INCOME_LEVEL, A.CUST_CREDIT_LIMIT,
    B.EDUCATION, B.AFFINITY_CARD, B.HOUSEHOLD_SIZE, B.OCCUPATION, B.YRS_RESIDENCE, B.Y_BOX_GAMES
FROM
    SH.CUSTOMERS A, SUPPLEMENTARY_DEMOGRAPHICS B
WHERE
    A.CUST_ID = B.CUST_ID;
```

![p.4](/Assets/p.4.png)
*OML Notebook Paragraph 4.*

5. **Cleanup any Previous Existing Model Objects**

I erased any previous **GLM models**, as well as their possible existent Settings and Diagnostics tables.

```sql
%script
-- Clean up any previous GLM Models for notebook repeatability
BEGIN
    DBMS_DATA_MINING.DROP_MODEL('GLMR_SH_Regr_sample');
EXCEPTION
    WHEN OTHERS THEN NULL;
END;
/

-- Clean up and drop any previous GLM Model Settings table for notebook repeatability
BEGIN EXECUTE IMMEDIATE 'DROP TABLE glmr_sh_sample_settings';
EXCEPTION WHEN OTHERS THEN NULL; END;
/

-- Clean up and drop any previous Model Diagnostics table for notebook repeatability
BEGIN EXECUTE IMMEDIATE 'DROP TABLE glmr_sh_sample_diag';
EXCEPTION WHEN OTHERS THEN NULL; END;
/
```

![p.5](/Assets/p.5.png)
*OML Notebook Paragraph 5.*

6. **Create GLM model settings table**

I proceeded to creating a specific table to store my new **GLM model** settings.

```sql
%sql
CREATE TABLE glmr_sh_sample_settings (
    setting_name VARCHAR2(30),
    setting_value VARCHAR2(4000)
);
```

![p.6](/Assets/p.6.png)
*OML Notebook Paragraph 6.*

7. **Turn on Automated Preparation and GLM Model Feature Selection**

Then, I cleared and repopulated the settings table of my model. As well of configuring the algorithm, I enabled automatic data preparation, and activated advanced options like feature selection and generation.

```sql
%script
BEGIN
    -- Clear previous settings
    DELETE FROM glmr_sh_sample_settings;

    -- Set the algorithm
    INSERT INTO glmr_sh_sample_settings (setting_name, setting_value) 
        VALUES (DBMS_DATA_MINING.ALGO_NAME, DBMS_DATA_MINING.ALGO_GENERALIZED_LINEAR_MODEL);

    -- Enable automatic data preparation
    INSERT INTO glmr_sh_sample_settings (setting_name, setting_value) 
        VALUES (DBMS_DATA_MINING.PREP_AUTO, DBMS_DATA_MINING.PREP_AUTO_ON);

    -- Enable feature selection
    INSERT INTO glmr_sh_sample_settings (setting_name, setting_value) 
        VALUES (DBMS_DATA_MINING.GLMS_FTR_SELECTION, DBMS_DATA_MINING.GLMS_FTR_SELECTION_ENABLE);

    -- Enable feature generation
    INSERT INTO glmr_sh_sample_settings (setting_name, setting_value) 
        VALUES (DBMS_DATA_MINING.GLMS_FTR_GENERATION, DBMS_DATA_MINING.GLMS_FTR_GENERATION_ENABLE);
END;
/
```

![p.7](/Assets/p.7.png)
*OML Notebook Paragraph 7.*

8. **Sample Data**

I split the data into a randomly selected 60% sample for model build and 40% hold out sample for model test.

```sql
%script
-- Split the Data into N1_TRAIN_DATA and N1_TEST_DATA
BEGIN
    EXECUTE IMMEDIATE 'CREATE OR REPLACE VIEW N1_TRAIN_DATA AS SELECT * FROM CUSTOMERS360 SAMPLE (60) SEED (1)';
    DBMS_OUTPUT.PUT_LINE('Created N1_TRAIN_DATA');
    EXECUTE IMMEDIATE 'CREATE OR REPLACE VIEW N1_TEST_DATA AS SELECT * FROM CUSTOMERS360 MINUS SELECT * FROM N1_TRAIN_DATA';
    DBMS_OUTPUT.PUT_LINE('Created N1_TEST_DATA');
END;
/
```

![p.8](/Assets/p.8.png)
*OML Notebook Paragraph 8.*

9. **Model Building**

Now I was able to build the GLM regression model for predicting **YRS_RESIDENCE**.

```sql
%script
-- Build the GLM regression model
DECLARE
    V_XLST DBMS_DATA_MINING_TRANSFORM.TRANSFORM_LIST;
BEGIN
    DBMS_DATA_MINING.CREATE_MODEL(
        MODEL_NAME          => 'GLMR_SH_REGR_SAMPLE',
        MINING_FUNCTION     => DBMS_DATA_MINING.REGRESSION,
        DATA_TABLE_NAME     => 'N1_TRAIN_DATA',
        CASE_ID_COLUMN_NAME => 'CUST_ID',
        TARGET_COLUMN_NAME  => 'YRS_RESIDENCE',
        SETTINGS_TABLE_NAME => 'GLMR_SH_SAMPLE_SETTINGS',
        XFORM_LIST          => V_XLST
    );
END;
/
```

![p.9](/Assets/p.9.png)
*OML Notebook Paragraph 9.*

10. **Model settings**

I displayed the GLM model settings.

```sql
%sql
SELECT 
    SETTING_NAME,
    SETTING_VALUE
FROM
    USER_MINING_MODEL_SETTINGS
WHERE 
    MODEL_NAME = 'GLMR_SH_REGR_SAMPLE'
ORDER BY 
    SETTING_NAME;
```

![p.10](/Assets/p.10.png)
*OML Notebook Paragraph 10.*

11. **Display GLM model signature**

I also listed all the input attributes used in the model, including their names and data types. This helps validate which features were incorporated during the model build phase.

```sql
%sql
SELECT
    ATTRIBUTE_NAME,
    ATTRIBUTE_TYPE
FROM
    USER_MINING_MODEL_ATTRIBUTES
WHERE 
    MODEL_NAME = 'GLMR_SH_REGR_SAMPLE'
ORDER BY 
    ATTRIBUTE_NAME;
```

![p.11](/Assets/p.11.png)
*OML Notebook Paragraph 11.*

12. **Show list of model views**

I inspected the model views, showing their names and types. These views provide access to detailed insights such as model settings, attributes, predictions, and diagnostics.

```sql
%sql
-- View the model views
SELECT
    VIEW_NAME,
    VIEW_TYPE
FROM
    USER_MINING_MODEL_VIEWS
WHERE
    MODEL_NAME='GLMR_SH_REGR_SAMPLE'
ORDER BY
    VIEW_NAME;
```

![p.12](/Assets/p.12.png)
*OML Notebook Paragraph 12.*

13. **Show GLM model summary**

```sql
%sql 
-- View the model summary statistics

SELECT
    NAME,
    NUMERIC_VALUE,
    STRING_VALUE
FROM 
    DM$VGGLMR_SH_REGR_SAMPLE
ORDER BY 
    NAME;
```

![p.13](/Assets/p.13.png)
*OML Notebook Paragraph 13.*

14. **Show GLM model coefficient statistics**

```sql
%sql
-- View model coefficient statistics

SELECT 
    FEATURE_EXPRESSION,
    COEFFICIENT,
    STD_ERROR,
    TEST_STATISTIC,
    P_VALUE,
    STD_COEFFICIENT,
    LOWER_COEFF_LIMIT,
    UPPER_COEFF_LIMIT
FROM
    DM$VDGLMR_SH_REGR_SAMPLE
ORDER BY 
    1;
```

![p.14](/Assets/p.14.png)
*OML Notebook Paragraph 14.*

15. **Display model features and p-values**

```sql
%sql
SELECT
    FEATURE_EXPRESSION,
    COEFFICIENT,
    P_VALUE
FROM
    DM$VDGLMR_SH_REGR_SAMPLE
ORDER BY
    FEATURE_EXPRESSION;
```

![p.15](/Assets/p.15.png)
*OML Notebook Paragraph 15.*

16. **Apply the GLM model to predict YRS_RESIDENCE and show Prediction_Details**

```sql
%sql
-- Make predictions with upper and lower bounds and include explanatory prediction details
SELECT CUST_ID,
       round(PREDICTION_YRS_RES,3) PRED_YRS_RES,
       round(PRED_LOWER_LIMIT,3) LOWER_PRED,
       round(PRED_UPPER_LIMIT,3) HIGHER_PRED,
       RTRIM(TRIM(SUBSTR(OUTPRED."Attribute1",17,100)),'rank="1"/>') FIRST_ATTRIBUTE,
       RTRIM(TRIM(SUBSTR(OUTPRED."Attribute2",17,100)),'rank="2"/>') SECOND_ATTRIBUTE,
       RTRIM(TRIM(SUBSTR(OUTPRED."Attribute3",17,100)),'rank="3"/>') THIRD_ATTRIBUTE,
       RTRIM(TRIM(SUBSTR(OUTPRED."Attribute4",17,100)),'rank="4"/>') FOURTH_ATTRIBUTE,
       RTRIM(TRIM(SUBSTR(OUTPRED."Attribute5",17,100)),'rank="5"/>') FIFTH_ATTRIBUTE
FROM (SELECT CUST_ID,
             PREDICTION(GLMR_SH_REGR_SAMPLE USING *) PREDICTION_YRS_RES,
             PREDICTION_BOUNDS(GLMR_SH_REGR_SAMPLE USING *).LOWER PRED_LOWER_LIMIT,
             PREDICTION_BOUNDS(GLMR_SH_REGR_SAMPLE USING *).UPPER PRED_UPPER_LIMIT,
             PREDICTION_DETAILS(GLMR_SH_REGR_SAMPLE USING *) PD
      FROM N1_TEST_DATA
      WHERE CUST_ID < 100015
ORDER BY CUST_ID) OUT,
XMLTABLE ('/Details'
          PASSING OUT.PD
          COLUMNS
            "Attribute1" VARCHAR2(100) PATH 'Attribute[1]',
            "Attribute2" VARCHAR2(100) PATH 'Attribute[2]',
            "Attribute3" VARCHAR2(100) PATH 'Attribute[3]',
            "Attribute4" VARCHAR2(100) PATH 'Attribute[4]',
            "Attribute5" VARCHAR2(100) PATH 'Attribute[5]'
         ) OUTPRED;
```

![p.16](/Assets/p.16.png)
*OML Notebook Paragraph 16.*

![p.16r](/Assets/p.16r.png)
*Results of OML Notebook Paragraph 16.*

17. **Show the GLM model predictions VS actuals**

```sql
%sql
-- Show predictions vs. actuals. The predictions look good.
SELECT 
    CUST_ID,
    round(PREDICTION(GLMR_SH_REGR_SAMPLE USING *), 1) PRED_YRS_RESIDENCE,
    YRS_RESIDENCE ACTUAL_YRS_RESIDENCE
FROM 
    N1_TEST_DATA
WHERE 
    CUST_ID <= 100030
ORDER BY 
    CUST_ID;
```

![p.17](/Assets/p.17.png)
*OML Notebook Paragraph 17.*

18. **Graph the GLM model predictions VS actuals grouped by HOUSE_HOLD_SIZE**

```sql
%sql
-- Show predictions vs. actuals in a scatter plot grouped by HOUSE_HOLD_SIZE.

SELECT 
    CUST_ID,
    round(PREDICTION(GLMR_SH_REGR_SAMPLE USING *), 1) PRED_YRS_RESIDENCE,
    YRS_RESIDENCE ACTUAL_YRS_RESIDENCE, CUST_GENDER, HOUSEHOLD_SIZE
FROM 
    N1_TEST_DATA
ORDER BY
    CUST_ID;
```

![p.18](/Assets/p.18.png)
*OML Notebook Paragraph 18.*

![p.18g](/Assets/p.18g.png)
*Graph generated with OML Notebook's Tools.*